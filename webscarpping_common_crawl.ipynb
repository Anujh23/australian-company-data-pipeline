{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62dfa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "import time\n",
    "\n",
    "# Constants\n",
    "INDEX_URL = \"https://index.commoncrawl.org/CC-MAIN-2025-13-index\"\n",
    "OUTPUT_FILE = \"australian_companies.csv\"\n",
    "TARGET_COUNT = 250000\n",
    "\n",
    "# Industry keywords to identify company sector\n",
    "INDUSTRY_KEYWORDS = {\n",
    "    \"banking\": [\"bank\", \"finance\", \"investment\", \"wealth\", \"superannuation\"],\n",
    "    \"retail\": [\"retail\", \"shop\", \"store\", \"shopping\", \"ecommerce\"],\n",
    "    \"technology\": [\"software\", \"technology\", \"it\", \"digital\", \"tech\"],\n",
    "    \"healthcare\": [\"health\", \"medical\", \"hospital\", \"clinic\", \"pharmaceutical\"],\n",
    "    \"education\": [\"education\", \"university\", \"school\", \"college\", \"training\"],\n",
    "    \"manufacturing\": [\"manufacturing\", \"production\", \"factory\", \"industrial\"],\n",
    "    \"construction\": [\"construction\", \"building\", \"development\", \"property\"],\n",
    "    \"mining\": [\"mining\", \"resources\", \"minerals\", \"energy\", \"oil\", \"gas\"],\n",
    "    \"agriculture\": [\"agriculture\", \"farming\", \"food\", \"agribusiness\"],\n",
    "    \"hospitality\": [\"hotel\", \"restaurant\", \"cafe\", \"tourism\", \"hospitality\"],\n",
    "    \"legal\": [\"legal\", \"law\", \"solicitor\", \"lawyer\", \"attorney\"],\n",
    "    \"consulting\": [\"consulting\", \"consultant\", \"advisory\", \"services\"]\n",
    "}\n",
    "\n",
    "\n",
    "def extract_company_name(url):\n",
    "    \"\"\"Extract potential company name from URL\"\"\"\n",
    "    domain = urlparse(url).netloc\n",
    "    \n",
    "    # Remove common TLDs and subdomains\n",
    "    domain = re.sub(r'\\.com\\.au$|\\.net\\.au$|\\.org\\.au$|\\.au$', '', domain)\n",
    "    domain = re.sub(r'^www\\.', '', domain)\n",
    "    \n",
    "    # Convert dashes and underscores to spaces\n",
    "    domain = domain.replace('-', ' ').replace('_', ' ')\n",
    "    \n",
    "    # Convert to title case for better readability\n",
    "    company_name = ' '.join(word.capitalize() for word in domain.split())\n",
    "    \n",
    "    return company_name\n",
    "\n",
    "\n",
    "def guess_industry(url, company_name):\n",
    "    \"\"\"Make a basic guess about the industry based on URL and company name\"\"\"\n",
    "    text = url.lower() + ' ' + company_name.lower()\n",
    "    \n",
    "    industry_matches = {}\n",
    "    for industry, keywords in INDUSTRY_KEYWORDS.items():\n",
    "        count = sum(1 for keyword in keywords if keyword in text)\n",
    "        if count > 0:\n",
    "            industry_matches[industry] = count\n",
    "    \n",
    "    if industry_matches:\n",
    "        return max(industry_matches, key=industry_matches.get)\n",
    "    return None\n",
    "\n",
    "\n",
    "def fetch_australian_websites():\n",
    "    \"\"\"Fetch Australian websites from Common Crawl index\"\"\"\n",
    "    all_records = []\n",
    "    page = 0\n",
    "    \n",
    "    with tqdm(total=TARGET_COUNT, desc=\"Fetching Australian websites\") as pbar:\n",
    "        while len(all_records) < TARGET_COUNT:\n",
    "            # Query the index for Australian domains\n",
    "            params = {\n",
    "                'url': '*.au',\n",
    "                'output': 'json',\n",
    "                'page': page\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                response = requests.get(INDEX_URL, params=params)\n",
    "                response.raise_for_status()\n",
    "                \n",
    "                # Each line in the response is a JSON record\n",
    "                records = [json.loads(line) for line in response.text.strip().split('\\n') if line]\n",
    "                \n",
    "                if not records:\n",
    "                    print(f\"No more records found after page {page}\")\n",
    "                    break\n",
    "                \n",
    "                # Process each record\n",
    "                for record in records:\n",
    "                    url = record.get('url')\n",
    "                    status = record.get('status')\n",
    "                    mime = record.get('mime-detected')\n",
    "                    \n",
    "                    # Skip non-HTML and error pages\n",
    "                    if not url or status != '200' or 'html' not in mime or 'robots.txt' in url:\n",
    "                        continue\n",
    "                    \n",
    "                    company_name = extract_company_name(url)\n",
    "                    industry = guess_industry(url, company_name)\n",
    "                    \n",
    "                    all_records.append({\n",
    "                        'url': url,\n",
    "                        'company_name': company_name,\n",
    "                        'industry': industry\n",
    "                    })\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "                    if len(all_records) >= TARGET_COUNT:\n",
    "                        break\n",
    "                \n",
    "                page += 1\n",
    "                # Be nice to the Common Crawl server\n",
    "                time.sleep(0.5)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching page {page}: {e}\")\n",
    "                time.sleep(5)  # Wait longer on error\n",
    "    \n",
    "    # Create a DataFrame and save to CSV\n",
    "    df = pd.DataFrame(all_records)\n",
    "    df.drop_duplicates(subset=['url'], inplace=True)\n",
    "    df.to_csv(OUTPUT_FILE, index=False)\n",
    "    \n",
    "    print(f\"Extracted {len(df)} Australian websites to {OUTPUT_FILE}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Starting extraction of Australian websites from Common Crawl...\")\n",
    "    fetch_australian_websites()\n",
    "    print(\"Extraction complete!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
