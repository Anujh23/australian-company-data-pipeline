{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f726e765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "DATASET_ID = \"5bd7fcab-e315-42cb-8daf-50b7efc2027e\"\n",
    "BASE_DIR = r\"C:\\Users\\anujh\\Desktop\\Firmable\\abn_bulk_extracts\"\n",
    "ZIP_DIR = BASE_DIR\n",
    "EXTRACT_DIR = os.path.join(BASE_DIR, \"unzipped\")\n",
    "OUTPUT_CSV = os.path.join(BASE_DIR, \"abr_output.csv\")\n",
    "\n",
    "\n",
    "def fetch_zip_files(dataset_id, download_dir):\n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "    api_url = f'https://data.gov.au/data/api/3/action/package_show?id={dataset_id}'\n",
    "    response = requests.get(api_url)\n",
    "    response.raise_for_status()\n",
    "    resources = response.json()['result']['resources']\n",
    "    zip_links = [r for r in resources if r['url'].lower().endswith('.zip')]\n",
    "\n",
    "    print(f\"Found {len(zip_links)} ZIP files to download.\")\n",
    "\n",
    "    for res in zip_links:\n",
    "        file_url = res['url']\n",
    "        file_name = file_url.split('/')[-1]\n",
    "        save_path = os.path.join(download_dir, file_name)\n",
    "        download_zip_file(file_url, save_path)\n",
    "\n",
    "\n",
    "def download_zip_file(url, path):\n",
    "    print(f\"Downloading {os.path.basename(path)}...\")\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code == 200:\n",
    "        with open(path, 'wb') as f:\n",
    "            f.write(resp.content)\n",
    "        print(f\"Saved: {path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download {url} - Status: {resp.status_code}\")\n",
    "\n",
    "\n",
    "def extract_all_zip_files(zip_dir, extract_to):\n",
    "    os.makedirs(extract_to, exist_ok=True)\n",
    "    for zip_path in glob.glob(os.path.join(zip_dir, \"*.zip\")):\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_to)\n",
    "        print(f\"Extracted: {zip_path}\")\n",
    "\n",
    "\n",
    "def parse_abn_xml(xml_path):\n",
    "    records = []\n",
    "    try:\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        for entity in root.findall(\".//ABR\"):\n",
    "            abn = entity.findtext(\"ABN\")\n",
    "            entity_type = entity.findtext(\"EntityType/EntityTypeText\")\n",
    "            status = entity.find(\"ABN\").attrib.get(\"status\")\n",
    "            start_date = entity.find(\"ABN\").attrib.get(\"ABNStatusFromDate\")\n",
    "            name = entity.findtext(\"MainEntity/NonIndividualName/NonIndividualNameText\")\n",
    "            state = entity.findtext(\"MainEntity/BusinessAddress/AddressDetails/State\")\n",
    "            postcode = entity.findtext(\"MainEntity/BusinessAddress/AddressDetails/Postcode\")\n",
    "\n",
    "            records.append({\n",
    "                \"ABN\": abn,\n",
    "                \"Entity Name\": name,\n",
    "                \"Entity Type\": entity_type,\n",
    "                \"Entity Status\": status,\n",
    "                \"Entity Address\": \"\",\n",
    "                \"Entity Postcode\": postcode,\n",
    "                \"Entity State\": state,\n",
    "                \"Entity Start Date\": start_date,\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse {xml_path}: {e}\")\n",
    "    return records\n",
    "\n",
    "\n",
    "def process_all_xml_files(xml_dir, output_csv):\n",
    "    all_records = []\n",
    "    for xml_file in glob.glob(os.path.join(xml_dir, \"*.xml\")):\n",
    "        records = parse_abn_xml(xml_file)\n",
    "        if records:\n",
    "            all_records.extend(records)\n",
    "            print(f\"Parsed {len(records)} records from {os.path.basename(xml_file)}\")\n",
    "        else:\n",
    "            print(f\"No records found in {os.path.basename(xml_file)}\")\n",
    "\n",
    "    if all_records:\n",
    "        df = pd.DataFrame(all_records)\n",
    "        write_header = not os.path.exists(output_csv)\n",
    "        df.to_csv(output_csv, mode='a', header=write_header, index=False)\n",
    "        print(f\"\\nOutput saved to: {output_csv}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    fetch_zip_files(DATASET_ID, ZIP_DIR)\n",
    "    extract_all_zip_files(ZIP_DIR, EXTRACT_DIR)\n",
    "    process_all_xml_files(EXTRACT_DIR, OUTPUT_CSV)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
